# Server Config
HOST=0.0.0.0
PORT=8000
WORKERS=4
RELOAD=true  # true for development, false for production
BASE_PATH=/api

# Development Mode - enables index dropping and other dev features
# Set to true in development, false in production
DEV_MODE=false

# AI API KEY
OPENAI_API_KEY=
GOOGLE_API_KEY=

# Redis Config
REDIS_HOST=
REDIS_PORT=
REDIS_USERNAME=
REDIS_PASSWORD=

# Redis HNSW (Hierarchical Navigable Small World) Index Parameters for Vector Search
REDIS_HNSW_M=24  # Number of bi-directional links per node (higher = better recall, more memory). Typical: 16-64
REDIS_HNSW_EF_CONSTRUCTION=200  # Size of dynamic candidate list during index build (higher = better quality, slower build). Typical: 100-500
REDIS_HNSW_EF_RUNTIME=100  # Size of dynamic candidate list during search (higher = better recall, slower search). Typical: 100-500

# Arize Config
ARIZE_SPACE_ID=
ARIZE_API_KEY=
ARIZE_PROJECT_NAME=

# Model Config
BASE_MODEL=gpt-4.1-mini
BASE_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_EMBEDDING_DIMENSIONS=1024

# MongoDB Config
MONGO_SRV_URI=  # Full SRV URI (preferred). If set, MONGO_USERNAME/PASSWORD/HOST/PORT are ignored
MONGO_DB_NAME=portfolio_agent
MONGO_USERNAME=  # Fallback if MONGO_SRV_URI not set
MONGO_PASSWORD=  # Fallback if MONGO_SRV_URI not set
MONGO_HOST=localhost  # Fallback if MONGO_SRV_URI not set
MONGO_PORT=27017  # Fallback if MONGO_SRV_URI not set

# Logging Config
LOG_LEVEL=INFO # DEBUG | INFO | WARNING | ERROR | CRITICAL
NO_COLOR=false # set to true/1/yes/on to disable colored logs; otherwise colors remain enabled
LOG_TIME_FORMAT=%H:%M:%S # strftime format, e.g. %H:%M:%S or %Y-%m-%d %H:%M:%S

# Context Configuration
MAX_TOKEN_THRESHOLD=50000
MAX_TURNS_TO_FETCH=100

# Tracing Config
ENABLE_TRACING=true
ENABLE_INPUT_GUARDRAIL=true
ENABLE_OUTPUT_GUARDRAIL=true

# LLM PROVIDERS
LLM_PROVIDER=openai  # openai
ENABLE_CHAT_COMPLETION=false  # true to use Chat Completion API, false for Responses API
MOCK_AI_RESPONSE=false  # true to use mock responses for testing (no actual LLM calls), false for real LLM calls
MOCK_AI_SUMMARY=true    # true to bypass LLM summary generation and use mock summary output
MOCK_AI_CHAT_NAME=true  # true to bypass LLM chat-name generation and use mock chat name output

# Cache
SKIP_CACHE=true

# Temp Directory
TMPDIR=./.tmp

# Session Configuration
DEFAULT_SESSION_NAME="New Chat"
TURNS_BETWEEN_CHAT_NAME=20  # Generate new chat name every N turns
MAX_CHAT_NAME_LENGTH=50  # Maximum length for generated chat names
MAX_CHAT_NAME_WORDS=5  # Maximum words for generated chat names

# Pagination Configuration
DEFAULT_MESSAGE_PAGE_SIZE=50
MAX_MESSAGE_PAGE_SIZE=100
DEFAULT_SESSION_PAGE_SIZE=20
MAX_SESSION_PAGE_SIZE=50
